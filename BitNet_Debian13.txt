1 Instalar paquetes previos
apt update
apt install lsb-release wget gnupg python3 python3-venv python3-dev python3-pip build-essential cmake clang git curl

2 BitNet requiere Clang versión 18 o superior para compilar correctamente su núcleo en C++. Debian 13 no trae versiones tan recientes por defecto, así que necesitas obtenerlas desde el repositorio oficial de LLVM.	 

bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"


3 Descargar e instalar miniconda

Ejecutamos con el usuario bitnet para que miniconda se isntale en /home/bitnet/:

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

Nos preguntara si deseamos automatizar el inicio de conda en la shell
Si respondes "yes", el instalador modificará tu archivo de configuración del shell (como ~/.bashrc, ~/.zshrc, etc.) para que se cargue automáticamente Conda cada vez que abras una terminal.

Si elijes "No" puedes activarlo manualmente solo cuando lo necesites, usando:

source ~/miniconda3/bin/activate

4 Crear un entorno conda para BitNet

conda create -n miniconda-bitnet-p3_9 python=3.9
Nos mostrara todos los paquetes a descargar e instalar, confirmamos con "y"

conda activate miniconda-bitnet-p3_9

Nos cambiara el promp de la terminal  con el nombre de miniconda-bitnet-p3_9
NOTA: ESTO SERA NECESARIO CADA VEZ QUE QUERRAMOS EJEUTAR EL MODELO

4 Descargar Bitnet 
git clone --recursive https://github.com/microsoft/BitNet.git

Entramos al directorio: 
cd BitNet

5 Instalar dependencias de python 

pip install -r requirements.txt

Ahora forzaremos a setup_env.py a usar Clang 19 como compilador en lugar del predeterminado del sistema (que suele ser gcc o una versión más antigua de clang).

⚠️ Sin esto:
El script puede usar un compilador incorrecto por defecto (como gcc o clang-14) que no soporta completamente las extensiones modernas de C++ requeridas por BitNet.

En Debian 13, clang-19 no es el compilador predeterminado, aunque lo hayas instalado.

export CC=/usr/bin/clang-19
export CXX=/usr/bin/clang++-19

6 Bajamos y compilamos el modelo 

Dentro de la ruta /home/usuario/BitNet ejecutamos: 

Descargar modelo:
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T

Compilar el modelo con cuantizacion I2_S(RAM recomendada 4–6 GB):
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

Compilar el modelo con cuantizacion TL2 (RAM recomendada 10–16 GB):
python setup_env.py -md models/BitNet-b1.58-2B-4T -q tl2

7 Por ultimo ejecutamos el modelo

Si es i2_s
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -cnv -p "lo que le queramos preguntar"

Si es TL2
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-tl2.gguf -cnv -p "lo que le queramos preguntar"


